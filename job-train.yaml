apiVersion: batch/v1
kind: Job
metadata:
  generateName: ${USER}-job-train-${JOB_SUFFIX}
  labels:
    eidf/user: ${USER}
    kueue.x-k8s.io/queue-name: ${QUEUE_NAME}
    kueue.x-k8s.io/priority-class: batch-workload-priority
spec:
  completions: 1
  parallelism: 1
  completionMode: Indexed
  backoffLimit: 0
  activeDeadlineSeconds: 864000
  ttlSecondsAfterFinished: 2592000
  template:
    metadata:
      labels:
        eidf/user: ${USER}
    spec:
      restartPolicy: OnFailure
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values:
                      # - NVIDIA-H200
                      - NVIDIA-A100-SXM4-80GB
      tolerations:
        - key: "eidf098"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
        - key: "eidf107"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
      containers:
        - name: pytorch-cuda12-1
          image: pytorch/pytorch:2.1.0-cuda12.1-cudnn8-devel
          workingDir: "/workspace/Lumina-Image-2.0"
          env:
            # --- START ADDITION ---
            - name: TZ
              value: "Etc/UTC"
            # --- END ADDITION ---
            - name: DEBIAN_FRONTEND # Keep this one too!
              value: "noninteractive"
            - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
              value: "1"
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_IB_DISABLE
              value: "1"
            - name: MAX_DELTA
              value: "${MAX_DELTA}"
            - name: NCCL_IB_HCA
              value: "^mlx5"
            - name: PYTHONPATH
              value: "/workspace/Lumina-Image-2.0"
          command: ["/bin/bash", "-c"]
          args:
            - |

              apt install git-all

              echo "Copying files to /pvc"
              cp -r /workspace/Lumina-Image-2.0 /pvc/
              cd /pvc/Lumina-Image-2.0

              # Set timezone non-interactively (alternative if TZ env var isn't enough)
              # echo 'Etc/UTC' > /etc/timezone
              # ln -fs /usr/share/zoneinfo/Etc/UTC /etc/localtime

              # Run apt update and install with -y and noninteractive frontend
              apt update && apt install -y --no-install-recommends \
                  wget \
                  git \
                  unzip \
                  zip \
                  libgl1 \
                  libglib2.0-0 \
                  ffmpeg \
                  tzdata \ # Explicitly install tzdata if needed \
                  cmake 
              
              echo "Installing GIT!!"
              apt-get -y install --no-install-recommends git

              # Clean up apt cache
              rm -rf /var/lib/apt/lists/*

              echo "Setting up environment..."
              export PYTHONPATH=$PYTHONPATH:/workspace/Lumina-Image-2.0
              

              python3 -m pip install --upgrade pip setuptools wheel
              pip install wavedrom
              python3 -m pip install --user lit
              pip install xtermcolor

              echo "Lumina-Image-2.0 Setup"
              pip install --upgrade pip
              pip install -r requirements.txt
              echo "Done!"

              echo "Installing flash-attn"
              pip install flash-attn==2.7.3 --no-build-isolation
              echo "Done!"

              echo "HF CLI"
              pip install -U "huggingface_hub[cli]"
              echo "Done!"

              echo "Logging into HF"
              chmod +x /pvc/Lumina-Image-2.0/hf_login.sh
              ./pvc/Lumina-Image-2.0/hf_login.sh.sh
              echo "Done!"

              echo "Starting training!!!"
              chmod +x scripts/run_1024_finetune.sh
              bash scripts/run_1024_finetune.sh

          resources:
            limits:
              nvidia.com/gpu: "4"
              cpu: "8"
              memory: "32Gi"
          volumeMounts:
            - name: workspace
              mountPath: /workspace
            - name: writeable
              mountPath: /pvc
            - name: dshm
              mountPath: /dev/shm
      volumes:
        - name: workspace
          nfs:
            server: 10.24.6.77
            path: /user/s2198939-eidf107
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
        - name: writeable
          persistentVolumeClaim:
            claimName: mimic-cxr2